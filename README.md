# Poetry Analyser
### by Jitkapat


## ที่มาและความสำคัญ  
โครงการนี้เริ่มต้นด้วยความคิดของข้าพเจ้าในฐานะผู้เรียนด้านวรรณคดีอังกฤษ และสนใจวรรณคดีประเภทกวีนิพนธ์ (poetry) เป็นพิเศษ 
สิ่งหนึ่งที่ต้องทำอยู่เป็นประจำเวลาอ่านกวีนิพนธ์คือวิเคราะห์รูปแบบ (form) ของตัวบท เช่น ทำนอง (meter) และสัมผัส (rhyme) 
ทั้งสองลักษณะนี้ของแต่ละบทอาจวิคราะห์ได้ไม่ยากนัก หากคลังคำศัพท์ในสมองของผู้วิเคราะห์มีมากเพียงพอ ทว่า มนุษย์แต่ละคนย่อมมีความรู้ที่จำกัด 
และอาจไม่สามารถวิเคราะห์รูปแบบของตัวบทกวีนิพนธ์บางบทได้โดยไม่อาศัยการค้นคว้าเพิ่มเติม โครงการนี้จึงจัดทำขึ้นเพื่อช่วยให้ผู้ใช้สามารถใช้เพื่อช่วยวิเคราะห์ 
ตัวบทกวีนิพนธ์ได้ง่ายขึ้น โดยให้โปรแกรมช่วยวิเคราะห์ในระดับเบื้องต้น อย่างทำนองโดยรวมของตัวบท และแบบแผนสัมผัส (rhyme pattern) 
เพื่อลดเวลาในการวิเคราะห์สิ่งเหล่านี้ของผู้ใช้ เพื่อที่จะได้ใช้เวลากับการวิเคราะห์เชิงความหมายที่ลึกซึ้งยิ่งขึ้นแทน
  
  ลักษณะโครงการเป็น python module ที่ผู้ใช้สามารถนำไปใช้เพื่อให้โปรแกรมวิเคราะห์ทำนองและสัมผัสของกวีนิพนธ์แต่ละบทได้โดยอัตโนมัติ  
  โดยโปรแกรมจะวิเคราะห์ข้อมูลต่าง ๆ ดังกล่าวโดยใช้ข้อมูลการออกเสียงคำจาก Carnegie Mellon University Pronouncing Dictionary และกฏทางสัทวิทยาภาษาอังกฤษ (English phonology) เบื้องต้น  

## วิธีการดำเนินงาน
ตัวโปรแกรมจัดทำขึ้นโดยใช้ข้อมูลคลังคำภาษาอังกฤษและการออกเสียงจาก Carnegie Mellon University Pronouncing Dictionary (CMU Dict) ประกอบกับกฏง่าย ๆ ที่เขียนขึ้นเพิ่มเติมในการกำกับการคำนวณว่ากวีนิพนธ์บทที่ป้อนเข้าให้แก่โปรแกรมนั้นมีทำนองและสัมผัสอย่างไรบ้าง  

ไฟล์ข้อมูล CMU Dict คือ cmudict-0.7b โดยดาวน์โหลดมาจากเว็บไซต์ [CMU Dict](http://www.speech.cs.cmu.edu/cgi-bin/cmudict) และทำการดัดแปลงเล็กน้อยเพื่อนำข้อมูลที่ไม่เกี่ยวกัลคลังคำออก (สามารถดูไฟล์ที่ดัดแปลงแล้วได้ที่ repository นี้)  

โค้ดส่วนอื่น ๆ สามารถดูได้ที่ repository เช่นกันในไฟล์ PoetryAnalyser.py  โดยตัวไฟล์มีการใช้ module เพิ่มเติมได้แก่ spacy เพื่อใช้ในการตัดแบ่งคำในบทกวีนิพนธ์

นอกจากนี้ยังมีการทดสอบการทำงานของโปรแกรมด้วยไฟล์ text กวีนิพนธ์ทั้งหมด 2 บท โดยได้แนบมาด้วยใน repository ได้แก่:  
- "Amazing Grace" (John Newton) ในไฟล์ amazinggrace.txt
- "Crossing the Bar" (Alfred, Lord Tennyson) ในไฟล์ crossing the bar.txt  



## ผลการดำเนินงาน 

โปรแกมรมีลักษณะเป็น python module ที่สามารถ import และสร้างobject เพื่อวิเคราะห์ตัวบทได้ทันที ดังนี้  


import PoetryAnalyser  
filename = 'yourfilename.txt'
PoetryAnalyser.Analyse(filename)

จากนั้นโปรแกรมจะทำการวิเคราะห์ตัวบทกวี และ print ช้อมูลได้แก่ จำนวนบรรทัด จังหวะ และแบบแผนคำสัมผัสในตัวบททันทีที่สร้าง object analyse ขึ้น  

นอกจากนี้ยังสามารถสร้าง object Analyse เก็บไว้เเพื่อดูข้อมูลต่าง ๆ เกี่ยวกับแต่ละส่วนย่อยตัวบทได้ ดังนี้

poem = Analyse(filename)  
poem.poem.lines # list ของแต่ละบรรทัดในตัวบท เป็นต้น  

(สามารถศึกษาการใช้งานแต่ละ object และ method ได้ที่ไฟล์ PoetryAnalyser.py)
 
ในขณะนี้ (version 0.1 beta) โปรแกรมสามารถใช้งานกับบทกวีนิพนธ์ได้ ตราบใดที่ตัวบทดังกล่าวมีลักษณะตรงกับเงื่อนไขดังนี้:  
1. บทกวีบทหนึ่งต่อหนึ่งไฟล์ โดยตัวไฟล์ลักษณะเป็นหนึ่งบรรทัดคั่นด้วย newline และกั้นระหว่าง stanza ด้วย newline  
1. ในตัวบทต้องไม่มีคำที่เมื่อตัดแบ่งด้วย spacy แล้วจะไม่มีคำที่ไม่พบใน CMU Dict ไม่เช่นนั้นจะไม่สามารถทำงานได้เพราะเกิด error (ส่วนใหญ่ปัญหาเกิดจากคำที่เป็น contraction เช่น don't เพราะจะแบ่งเป็น do / n't ซึ่ง n't ไม่พบใน CMU Dict)
ดังนั้นจึงมีช้อจำกัดในการวิเคราะห์อยู่บ้าง ว่าสามารถใช้ได้เฉพาะกับบางบทกวีเท่านั้นในเวอร์ชั่นปัจจุบัน  

การทำงานถือว่าทำได้ดีพอสมควรในส่วนของคำสัมผัสที่แม่นยำ (ความถูกต้องมากกว่า 90%) แต่ทำได้ไม่ดีนักในส่วนของทำนอง (ความถูกต้องต่ำกว่า 50%) อาจเป็นเพราะกฏที่เขียนขึ้นไม่สามารถใช้วิเคราะห์พยางค์หนัก-เบา (weak/strong syllables) ในบริบทที่ยาวกว่า 1 คำได้ โดยในเวอร์ชั่นปัจจุบันใช้กฏง่าย ๆ ได้แก่ content word ได้รับพยางค์หนักตาม dictionary และ function word เป็นพยางค์เบาทั้งหมด ซึ่งใช้หลักการแบ่งกลุ่มคำดังกล่าวผ่าน token.pos_ ของ spacy ซึ่งกฏดังกล่าวยังไม่ดีเพียงพอเทียบเท่ากับการอ่านออกเสียงหนักเบาในประโยคของมนุษย์ ดังนั้นจึงวิเคราะห์พยางค์หนัก-เบาของแต่บะบรรทัดไม่ตรงกับเสียงตามการพูดธรรมชาติ (natural speech) และส่งผลให้วิเคราะห์ทำนองผิดพลาด

## อุปสรรค
อุปสรรคหลักในการทำโครงการนี้ได้แก่เวลาและข้อมูลที่จำกัด เนื่องจากการวิเคราะห์เสียงรวมถึงกฏการออกเสียงต่าง ๆ นั้นอาจต้องมีการศึกษาเพิ่มเติมจำนวนมาก และใช้ฐานข้อมูลที่กว้างขวางมากกว่าเพียงแหล่งเดียวอย่างในปัจจุบัน ดังเช่นในโครงการ [Prosodic](https://pypi.org/project/prosodic/) ที่ใช้ CMU Dict ควบคู่กับ speech recogniser ในการวิเคราะห์เสียงของแต่ละคำและบรรทัด ซึ่งในโครงการนี้ไม่สามารถศึกษาได้มากเพียงพอภายใต้เงื่อนไขเวลาที่จำกัด นอกจากนั้นกฏที่ใช้ในการวิเคราะห์ยังขาดความละเอียด มีการวิเคราะห์เพียงชั้นเดียว คือเมื่อพยางค์หนักเบาในบทกวีตรงกับรูปแบบที่ป้อนไว้ล่วงหน้า โปรแกรมก็จะสรุปผลว่าเป็นรูปแบบนั้น ๆ ทันที ต่างจาก Prosodic ที่ใช้การกลยุทธ์วิเคราะห์หลายกลยุทธ์พร้อมกัน จากนั้นจึงทำการคำนวณว่ารูปแบบใดน่าจะถูกต้องที่สุด เพื่อให้ได้ผลลัพธ์ที่เที่ยงตรงยิ่งขึ้น การวิเคราะห์และสร้างกฏเช่นนี้จำเป็นต้องใช้เวลามากเช่นกัน  

นอกจากนั้น module ที่เลือกใช้ในการตัดแบ่งคำอย่าง spacy ยังไม่สามารถทำงานได้ดีนักกับ CMU Dict ดังที่มักมีปัญหากับ contractions โดยอาจต้องมีการพิจารณาปรับแต่งโค้ดให้ทำงานร่วมกันได้ดีขึ้น หรืออาจเปลี่ยนไปใช้ module การตัดแบ่งคำตัวอื่นที่สามารถตัดแบ่งคำและยังเก็บข้อมูล เช่น tag ของแต่ละคำไว้ได้เช่นเดียวกัล spacy  

## สรุปผล
เนื่องด้วยเวลารวมถึงข้อมูลที่จำกัด โครงการนี้อาจมีประสิทธิภาพในการวิคราะห์ทำนองของกวีนิพนธ์ที่ไม่ดีนัก รวมถึงการใช้งานโปรแกรมที่ค่อนข้างจำกัด ไม่ครอบคลุมบทกวีนิพนธ์อย่างกว้าง ๆ ดังที่ได้ตั้งใจไว้ อย่างไรก็ตามส่วนการวิเคราะห์คำสัมผัสค่อนข้างแม่นยำพอสมควร และตัวโปรแกรมยังสามารถพัฒนาให้ใช้งานดีขึ้นได้โดยใช้เวลาศึกษาเพิ่มเติม จากการศึกษาการวิเคราะห์เชิงสัทวิทยา โดยเฉพาะด้านสัทสัมพันธ์จากโครงการ NLP ที่วิเคราะห์กวีนิพนธ์ เช่น Prosodic และโครงการอื่น ๆ เพื่อใช้เป็นแบบอย่าง หรืออาจนำมาใช้ร่วมกับโค้ดในโครงการนี้ เป็นต้น
